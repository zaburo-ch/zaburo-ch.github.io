<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on ZABURO app</title>
    <link>https://zaburo-ch.github.io/post/</link>
    <description>Recent content in Posts on ZABURO app</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 19 Feb 2016 21:25:37 +0900</lastBuildDate>
    <atom:link href="https://zaburo-ch.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Pythonで 多層パーセプトロン を実装する</title>
      <link>https://zaburo-ch.github.io/post/mlp/</link>
      <pubDate>Fri, 19 Feb 2016 21:25:37 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/mlp/</guid>
      <description>&lt;p&gt;前回は古典的Q学習を実装しましたが、次はニューラルネットを用いたQ学習として、&lt;br /&gt;
&lt;a href=&#34;http://ml.informatik.uni-freiburg.de/_media/publications/rieecml05.pdf&#34;&gt;Neural Fitted Q Iteration&lt;/a&gt;を使ったQ学習を実装しようと考えています。&lt;/p&gt;

&lt;p&gt;今回はその前の勉強として、&lt;br /&gt;
誤差逆伝播法を用いた多層パーセプトロンをNumPyだけで実装してみます。&lt;br /&gt;
誤差逆伝播法についてはこちらのスライドが詳しいです。&lt;/p&gt;

&lt;p&gt;&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/1T0PJeFTRBMnCG?startSlide=32&#34; width=&#34;425&#34; height=&#34;355&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt;&lt;br /&gt;
&lt;a href=&#34;//www.slideshare.net/weda654/3-45366686&#34; title=&#34;わかりやすいパターン認識_3章&#34; target=&#34;_blank&#34;&gt;わかりやすいパターン認識_3章&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;コードはこんな感じ。
&lt;script src=&#34;https://gist.github.com/zaburo-ch/7ab05a6dda71b5ccfe4f.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;活性化関数は全てシグモイド関数で、コスト関数は残差の平方和を用いました。&lt;br /&gt;
各層はforwardで出力を計算して、&lt;br /&gt;
backwardで前の層の誤差を計算しつつ W や b の更新を行います。&lt;br /&gt;
tanhなどの層も同じような関数を実装してMLPのinitを適宜変えれば使える(はず)。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://deeplearning.net/tutorial/mlp.html&#34;&gt;DeepLearningTutorialsのMLPのコード&lt;/a&gt;っぽくしたくて、&lt;br /&gt;
&lt;a href=&#34;http://blog.yusugomori.com/post/40250499669/python%E3%81%AB%E3%82%88%E3%82%8Bdeep-learning%E3%81%AE%E5%AE%9F%E8%A3%85deep-belief-nets-%E7%B7%A8&#34;&gt;DeepLearningTutorialsのDBNをNumPyで実装した方のコード&lt;/a&gt;とか、&lt;br /&gt;
&lt;a href=&#34;http://aidiary.hatenablog.com/entry/20140201/1391218771&#34;&gt;NumPyでMLPを実装を実装した方のコード&lt;/a&gt;などを参考に書きました。&lt;/p&gt;

&lt;p&gt;各所に載っている式を見る限りは出力層も活性化関数を使うっぽいんですが、&lt;br /&gt;
Chainerの多層パーセプトロンのサンプルをはじめとして、&lt;br /&gt;
出力層で線形変換するだけ(活性化関数を使わない)のものが結構あって混乱しました。&lt;br /&gt;
たぶんシグモイド関数やtanhだと出力できる範囲が狭くて不便なので&lt;br /&gt;
出力層だけ恒等関数使ってるんだろうという感じでとりあえず考えています。&lt;br /&gt;
先のNFQの論文で、全ての層でシグモイドを使ったみたいなことが書いてあったので、&lt;br /&gt;
今回は出力層にもシグモイド関数を使うことにしています。&lt;br /&gt;
あと出力層での誤差も、出力層の活性化関数の微分をかけるのかどうかがわからなくて&lt;br /&gt;
結構悩みましたが、スライドの式に従ってかけることにしました。&lt;/p&gt;

&lt;p&gt;また、確率的勾配降下法(SGD)でミニバッチを使った学習ができるように書きましたが、&lt;br /&gt;
ミニバッチを使う時に W や b の更新をどうやるのかがよくわからなくて、&lt;br /&gt;
結局ループ回して学習パターン1つずつ使って更新を行うようにしました。&lt;br /&gt;
出力層の時点で誤差の和をとってそれを伝播するんだと思ったのですが、&lt;br /&gt;
そしたらそれと掛け合わせる前の層の出力はどうするんだ！？ってなって&lt;br /&gt;
結局わからず、まあ結局やってること大体一緒でしょってことでこの形にしました。&lt;/p&gt;

&lt;p&gt;結果はこんな感じになります。赤が教師信号、青がMLPの出力で、&lt;br /&gt;
左が1000回反復した場合、右が10000回反復した場合です。&lt;br /&gt;
&lt;img src=&#34;https://zaburo-ch.github.io/images/mlp_approximate_abs_1000.png&#34; width=&#34;300px&#34; /&gt;
&lt;img src=&#34;https://zaburo-ch.github.io/images/mlp_approximate_abs_10000.png&#34; width=&#34;300px&#34; /&gt;&lt;/p&gt;

&lt;p&gt;たぶん学習できていると思うのですが、&lt;br /&gt;
いまいちうまくいっているのか確証が持てなかったので、&lt;br /&gt;
同じネットワークをChainerでも実装してみました。&lt;/p&gt;

&lt;p&gt;コードは&lt;a href=&#34;https://gist.github.com/zaburo-ch/8f4fe27e898b42a38635&#34;&gt;ここ&lt;/a&gt;。Tutorialのものをちょっといじっただけです。&lt;/p&gt;

&lt;p&gt;結果は次の通り。&lt;br /&gt;
&lt;img src=&#34;https://zaburo-ch.github.io/images/mlp_approximate_abs_chainer_1000.png&#34; width=&#34;300px&#34; /&gt;
&lt;img src=&#34;https://zaburo-ch.github.io/images/mlp_approximate_abs_chainer_10000.png&#34; width=&#34;300px&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Chainerの方が若干うまく近似できていますが、&lt;br /&gt;
概ね同じような感じの結果が得られたので、自分で書いた方も大丈夫なはず。&lt;/p&gt;

&lt;p&gt;実行時間はNumPyだけの方がかなり早いです。&lt;br /&gt;
ただ自分で微分する必要もなく適当に層つなぐだけで出来ちゃったのでChainerすごい&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pythonで Q学習 を実装する</title>
      <link>https://zaburo-ch.github.io/post/q-learning/</link>
      <pubDate>Sun, 14 Feb 2016 14:28:18 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/q-learning/</guid>
      <description>&lt;p&gt;Deep Q-Networkについて調べてみたら面白い記事を見つけました。&lt;br /&gt;
&lt;a href=&#34;http://qiita.com/Ugo-Nama/items/08c6a5f6a571335972d5&#34;&gt;DQNの生い立ち　＋　Deep Q-NetworkをChainerで書いた&lt;br /&gt;
http://qiita.com/Ugo-Nama/items/08c6a5f6a571335972d5&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;この記事を読んで、Deep Q-Networkが&lt;br /&gt;
Q学習 -&amp;gt; Q-Network -&amp;gt; Deep Q-Network という流れ生まれたものだということがわかりました。&lt;br /&gt;
この流れをPythonで実装しながら辿ってみようと思います。&lt;/p&gt;

&lt;p&gt;今回はQ学習を実装します。&lt;br /&gt;
Q学習について下記のページに詳しく載っているので割愛します。&lt;br /&gt;
&lt;a href=&#34;http://www.sist.ac.jp/~kanakubo/research/reinforcement_learning.html&#34;&gt;強化学習&lt;br /&gt;
http://www.sist.ac.jp/~kanakubo/research/reinforcement_learning.html&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://sysplan.nams.kyushu-u.ac.jp/gen/edu/RL_intro.html&#34;&gt;強化学習とは？&lt;br /&gt;
http://sysplan.nams.kyushu-u.ac.jp/gen/edu/RL_intro.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;まず、Q学習で適応する環境として次のような簡単な環境を考えます。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;環境の状態は、&#39;A&#39;または&#39;B&#39;からなる長さ8の文字列で表され、  
その文字列にはある法則により得点がつけられる。  
プレイヤーはその法則についての知識を予め持たないが、  
文字列中の任意の1文字を選んで&#39;A&#39;または&#39;B&#39;に置き換えることができ、  
その結果、その操作による得点の変化量を報酬として受け取る。  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;たぶんマルコフ決定過程になっていると思います。マルコフ性、&lt;a href=&#34;http://ibisforest.org/index.php?%E3%82%A8%E3%83%AB%E3%82%B4%E3%83%BC%E3%83%89%E6%80%A7&#34;&gt;エルゴート性&lt;/a&gt;も持つはず。&lt;/p&gt;

&lt;p&gt;文字列に得点をつける法則はなんでも良いのですが、&lt;br /&gt;
今回は、特定の文字列(単語)に次のように得点を割り当てて、&lt;br /&gt;
{&amp;ldquo;A&amp;rdquo;: 1, &amp;ldquo;BB&amp;rdquo;: 1, &amp;ldquo;AB&amp;rdquo;: 2, &amp;ldquo;ABB&amp;rdquo;: 3, &amp;ldquo;BBA&amp;rdquo;: 3, &amp;ldquo;BBBB&amp;rdquo;: 4}&lt;br /&gt;
文字列中に含まれる単語の合計得点を文字列の得点とするということにします。&lt;br /&gt;
例えば&amp;rdquo;AAAAAAAA&amp;rdquo;なら8点(1 * 8)、&amp;rdquo;AAAAAAAB&amp;rdquo;なら9点(1 * 7 + 2)です。&lt;/p&gt;

&lt;p&gt;環境のとりうる状態は長さ8のそれぞれに&amp;rsquo;A&amp;rsquo;, &amp;lsquo;B&amp;rsquo;の2通りあるので2^8通りあり、&lt;br /&gt;
アクションは、何もしないのと、位置1~8のそれぞれを&amp;rsquo;A&amp;rsquo;または&amp;rsquo;B&amp;rsquo;なのでを計17通りあります。&lt;br /&gt;
今回のコードでは状態は文字列、アクションは整数(0~16)で管理します。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/zaburo-ch/9ee5fd731d40d47c82ad.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;先述した強化学習の記事では、Q学習の学習中に、&lt;br /&gt;
一定の回数遷移を繰り返した後、状態をs0に戻すものとそうでないものがあり、&lt;br /&gt;
どちらを採用するか悩んだので QLearning(n_rounds, t_max)として&lt;br /&gt;
2重のループにすることで一応どちらの方法でも実行できるようにしました。&lt;/p&gt;

&lt;p&gt;これを実行結果はこんな感じ&lt;br /&gt;
&lt;img src=&#34;https://zaburo-ch.github.io/images/q_learning_figure_1.png&#34; alt=&#34;/images/q_learning_figure_1.png&#34; /&gt;
軸のラベルを書き忘れていますが、&lt;br /&gt;
横軸が外側のループが回った数で、縦軸がそれまでに学習したQを使ってt_max回遷移した時のスコアですね。&lt;br /&gt;
&amp;ldquo;ABBBBBBB&amp;rdquo;に遷移して終わるのとき最大値28をとるのですが、&lt;br /&gt;
約900セット(t_max * 900回)の学習でそれを実現する遷移ができるようになっています。&lt;/p&gt;

&lt;p&gt;この問題だとイマイチQ学習のイメージがつかみにくいので、&lt;br /&gt;
素直に最短路問題とかにしとけば良かったなーと思っています。&lt;/p&gt;

&lt;p&gt;最短路問題を使ったわかりやすい例はこちら&lt;br /&gt;
&lt;a href=&#34;http://d.hatena.ne.jp/poor_code/20090628/1246176165&#34;&gt;Q学習による最短経路学習 - poor_codeの日記&lt;br /&gt;
http://d.hatena.ne.jp/poor_code/20090628/1246176165&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Androidアプリ「スマホさがし」公開しました</title>
      <link>https://zaburo-ch.github.io/post/release-smapho-sagashi/</link>
      <pubDate>Wed, 09 Dec 2015 17:22:31 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/release-smapho-sagashi/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://zaburo-ch.github.io/images/smapho_sagashi_promo1.jpg&#34; alt=&#34;プロモ画像&#34; /&gt;&lt;/p&gt;

&lt;p&gt;結構前の話ですが、「スマホさがし」というAndroidアプリを公開しました。&lt;br /&gt;
Webページから紛失したスマホのアラームを鳴らせるという機能だけの簡単なアプリです。&lt;/p&gt;

&lt;p&gt;最近家でスマホをなくすことが多く、同様のアプリを入れようと思ったのですが、&lt;br /&gt;
スマホ無くて探してるのに「SMSで操作できます」みたいなアプリとか、&lt;br /&gt;
Webページからの操作に何でも彼んでも権限与えまくってる恐怖のアプリとかしか見つからなかったので、&lt;br /&gt;
自分用に最小限のものをサクッと作ってみました。&lt;/p&gt;

&lt;p&gt;Androidアプリにハマっていたのが2年前くらいなのですが、&lt;br /&gt;
今はEclipseじゃなくてAndroidStudioになってて便利だし、&lt;br /&gt;
適当に作ってもそれなりのデザインになるように設計されてるしで感動ものでした。&lt;/p&gt;

&lt;p&gt;ということで「スマホさがし」よろしくお願いします。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://play.google.com/store/apps/details?id=io.github.zaburo_ch.smaphosagashi&#34;&gt;&lt;img alt=&#34;Get it on Google Play&#34; src=&#34;https://developer.android.com/images/brand/en_generic_rgb_wo_45.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Forexiteから為替データを取得するスクリプトを書いた【Python】</title>
      <link>https://zaburo-ch.github.io/post/get-exchange-data-from-forexite/</link>
      <pubDate>Thu, 08 Oct 2015 22:26:21 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/get-exchange-data-from-forexite/</guid>
      <description>&lt;p&gt;書きました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.forexite.com/&#34;&gt;Forexite&lt;/a&gt;から分足データをダウンロードしてきて&lt;br /&gt;
解凍したものを適当な形にpandasで加工してcsvで出力する、というのを n 日分行います。&lt;br /&gt;
ひとまず n は200にしているので、そのままコピペして実行すれば200日分のデータが集まるはずです。&lt;/p&gt;

&lt;p&gt;Forexiteのデータは１日毎に分けられているのですが、&lt;br /&gt;
これから使う用途ではその方が都合が良いのでそのままにしてます。&lt;/p&gt;

&lt;p&gt;コードは以下の通り。&lt;br /&gt;
&lt;script src=&#34;https://gist.github.com/zaburo-ch/2ad144ae43a10844a646.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;ブログ用に処理を綺麗に関数にまとめたかったのですが、&lt;br /&gt;
逆に強引な書き方が増えてしまいました&amp;hellip;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>pandasで為替データを扱う【Python】</title>
      <link>https://zaburo-ch.github.io/post/handle-exchange-data-by-pandas/</link>
      <pubDate>Thu, 08 Oct 2015 00:59:54 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/handle-exchange-data-by-pandas/</guid>
      <description>&lt;p&gt;データ分析を本格的にやっていきたいと考えていて、&lt;br /&gt;
その足がかりとしてpandasの使い方を勉強をしています。&lt;/p&gt;

&lt;p&gt;今回は為替データを扱ってみたいと思います。&lt;br /&gt;
&lt;a href=&#34;https://www.forexite.com/&#34;&gt;Forexite&lt;/a&gt;というサイトで分足データが無料でダウンロードできるので、これを使います。&lt;br /&gt;
さっそく&lt;a href=&#34;https://www.forexite.com/free_forex_quotes/2015/10/061015.zip&#34;&gt;こちら(2015年10月6日分)&lt;/a&gt;からzipをダウンロードしてきて解凍すると&lt;br /&gt;
色々な通貨のデータが一つのtxtファイルにまとまっています。&lt;/p&gt;

&lt;p&gt;USDJPYのデータを抽出し5分足の終値と&lt;br /&gt;
ボリンジャーバンド、指数加重移動平均をプロットするところまでやります。&lt;/p&gt;

&lt;p&gt;IPythonで試行錯誤しながらやったものをまとめたコードが以下の通りです。
&lt;script src=&#34;https://gist.github.com/zaburo-ch/12e9ada46ee2b7a16e5f.js&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;こんな感じのグラフが表示されます。&lt;br /&gt;
&lt;img src=&#34;https://zaburo-ch.github.io/images/pandas_study_01.png&#34; alt=&#34;図1&#34; /&gt;&lt;br /&gt;
&amp;lt;DTYYYYMMDD&amp;gt;と&amp;lt;TIME&amp;gt;をマージする部分の強引さが酷いですね。&lt;br /&gt;
きっともっとスマートにできるんだろうなぁ&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Go言語でリダイレクト先のURLを取得する</title>
      <link>https://zaburo-ch.github.io/post/get-redirect-url-in-go/</link>
      <pubDate>Sat, 12 Sep 2015 00:08:08 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/get-redirect-url-in-go/</guid>
      <description>

&lt;p&gt;タイトルのとおりGoでリダイレクト先のURLを取得します。&lt;br /&gt;
Goでは普通にClientを使ってGETやらHEADリクエストを行うと、&lt;br /&gt;
リダイレクトがあったとき自動的にリダイレクト先の内容をとってくるようになっているので、&lt;br /&gt;
今回のようにリダイレクト先に行く必要の無い特殊なケースでは、&lt;br /&gt;
リダイレクト時の動作を変更するか、より低レベルのメソッドを利用することで対応します。&lt;/p&gt;

&lt;p&gt;参考にしたページ&lt;br /&gt;
&lt;a href=&#34;http://stackoverflow.com/questions/23297520/how-can-i-make-the-go-http-client-not-follow-redirects-automatically&#34;&gt;rest - How Can I Make the Go HTTP Client NOT Follow Redirects Automatically? - Stack Overflow&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;リダイレクト時の動作を変更する:7a97346472b573b7ec258a58d0cd30e4&#34;&gt;リダイレクト時の動作を変更する&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;Client.CheckRedirect func(req *Request, via []*Request) error&lt;/code&gt;&lt;br /&gt;
がリダイレクト時の動作を定めているためこれを変更します。&lt;br /&gt;
CheckRedirectがerrorを返すと、Clientはリダイレクト先を取得する代わりに&lt;br /&gt;
前のレスポンスの内容とそのerror(wrapped in a url.Error)を返します。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/zaburo-ch/98a1a0bfef742111020b.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;30行目では型アサーションを用いてRedirectAttemptedErrorが起こったかを確認しています。&lt;br /&gt;
HEADリクエストの場合もBodyをcloseしなきゃいけないのかはちょっとわかりませんが、&lt;br /&gt;
&lt;a href=&#34;http://golang.org/pkg/net/http/#Response&#34;&gt;これ&lt;/a&gt;を見る限りは必要そうなのでcloseしています。&lt;/p&gt;

&lt;h2 id=&#34;より低レベルのメソッドを利用する:7a97346472b573b7ec258a58d0cd30e4&#34;&gt;より低レベルのメソッドを利用する&lt;/h2&gt;

&lt;p&gt;http.TransportのRoundTripメソッドを使ってリクエストを行います。&lt;/p&gt;

&lt;script src=&#34;https://gist.github.com/zaburo-ch/99e58cf8fa9d3d11bd6a.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Transportの設定難しそうだったのでひとまずhttp.DefaultTransport使ってます。&lt;br /&gt;
ClientはStatusCodeが301,302,303,307の時にリダイレクトの処理を行うので、&lt;br /&gt;
たぶんこの20行目の書き方でも上手く行くはずです。&lt;br /&gt;
複数の値のどれかと一致すればtrueみたいな書き方がわからなかったので&lt;br /&gt;
愚直に4つ書いて並べてあります。なんかいい方法あるんでしょうか。&lt;br /&gt;
Pythonみたいにin演算子とかあればいいんですけどね。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Google Picker API を使ってみる</title>
      <link>https://zaburo-ch.github.io/post/quick-start-google-picker-api/</link>
      <pubDate>Thu, 06 Aug 2015 01:41:08 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/quick-start-google-picker-api/</guid>
      <description>&lt;p&gt;Google Driveのファイルを利用できるPicker APIを
GAE上で使ってみたのでメモっておきます。&lt;br /&gt;
クライアントIDが何かとか詳しい話は抜きにしてとにかく動かすまで。&lt;/p&gt;

&lt;p&gt;こちらのガイドに従ってやります。&lt;br /&gt;
&lt;a href=&#34;https://developers.google.com/picker/docs/&#34;&gt;https://developers.google.com/picker/docs/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;まずPciker APIを有効にします。&lt;br /&gt;
&lt;a href=&#34;https://console.developers.google.com/&#34;&gt;Google Developers Console&lt;/a&gt;にログインしてAPIを使うプロジェクトのページに入ります。&lt;br /&gt;
左側のサイドバーの「APIと認証」-&amp;gt;「API」を選択。&lt;br /&gt;
Pickerとかで検索して「Google Picker API」を選択しAPIを有効にします。&lt;/p&gt;

&lt;p&gt;次にクライアントIDとAPIキーを作成します。&lt;br /&gt;
「APIと認証」-&amp;gt;「認証情報」から2つとも作成できます。&lt;/p&gt;

&lt;p&gt;クライアントIDの方はウェブアプリケーションを選択し、&lt;br /&gt;
「JavaScript 生成元」にはAPIを使用するページのオリジンを指定。&lt;br /&gt;
今回はlocalhost:8080でも動いて欲しいので次の二つを指定しました。&lt;br /&gt;
http://プロジェクトID.appspot.com/&lt;br /&gt;
&lt;a href=&#34;http://localhost:8080/&#34;&gt;http://localhost:8080/&lt;/a&gt;&lt;br /&gt;
リダイレクトURLはよくわからなかった。とりあえず、&lt;br /&gt;
&lt;a href=&#34;http://localhost:8080/oauth2callback&#34;&gt;http://localhost:8080/oauth2callback&lt;/a&gt;&lt;br /&gt;
みたいな感じで指定してるけどたぶん意味ないです。&lt;/p&gt;

&lt;p&gt;APIキーの方はブラウザキーを選択。&lt;br /&gt;
リファラーはクライアントIDの時と同じ感じで&lt;br /&gt;
http://プロジェクトID.appspot.com/*&lt;br /&gt;
&lt;a href=&#34;http://localhost:8080/*&#34;&gt;http://localhost:8080/*&lt;/a&gt;&lt;br /&gt;
としました。&lt;/p&gt;

&lt;p&gt;これでクライアントIDとAPIキーが取得できたので&lt;br /&gt;
先のガイドの「The &amp;ldquo;Hello World&amp;rdquo; Application」のとおりにページを用意して&lt;br /&gt;
developerKeyとclientIdを書き換えればとりあえず動きます。&lt;/p&gt;

&lt;p&gt;このスクリプトの流れは、&lt;br /&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;script type=&amp;ldquo;text/javascript&amp;rdquo; src=&amp;ldquo;&lt;a href=&#34;https://apis.google.com/js/api.js?onload=onApiLoad&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&#34;&gt;https://apis.google.com/js/api.js?onload=onApiLoad&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;&lt;/a&gt;
&lt;/code&gt;&lt;/pre&gt;
でGoogle API Loader scriptを読み込む。&lt;br /&gt;
読み込みが終わると onload=onApiLoad で指定しているonApiLoadが呼ばれて&lt;br /&gt;
authとpickerのスクリプトが読み込まれる。&lt;br /&gt;
両方読み込まれるとcreatePicker()の内容が実行されて&lt;br /&gt;
pickerのインスタンスが作成、可視化される。&lt;br /&gt;
という感じになっています。&lt;/p&gt;

&lt;p&gt;pickerの生成時にコールバック用の関数とかいろいろ指定できるのですが、&lt;br /&gt;
addView()の部分がキモで、ここで表示されるファイルの種類を指定しています。&lt;br /&gt;
指定方法についてはガイドの「Showing Different Views」に表が載っていて&lt;br /&gt;
サンプルの通りだとPicasaのWeb Albumsにある写真が表示されるようになっています。&lt;/p&gt;

&lt;p&gt;こことscopeを表に従って変えればGoogle Driveのアイテムとかも表示できるのですが&lt;br /&gt;
全部取得してしまうとごちゃごちゃになるのでsetMimeTypesでMIME Typeを指定します。&lt;br /&gt;
MIME Typeは&lt;a href=&#34;http://www.plala.or.jp/access/community/phps/mime.html&#34;&gt;MIME Type 一覧表&lt;/a&gt;を見て適当に。&lt;br /&gt;
例えばpdfだけを表示するようにしたい場合は次のようにします。&lt;br /&gt;
&lt;pre&gt;&lt;code&gt;function createPicker() {
    var view = new google.picker.View(google.picker.ViewId.DOCS);
    view.setMimeTypes(&amp;ldquo;application/pdf&amp;rdquo;);
    if (pickerApiLoaded &amp;amp;&amp;amp; oauthToken) {
        var picker = new google.picker.PickerBuilder().
            addView(view).
            setLocale(&amp;lsquo;ja&amp;rsquo;).
            setOAuthToken(oauthToken).
            setDeveloperKey(developerKey).
            setCallback(pickerCallback).
            build();
        picker.setVisible(true);
    }
}
&lt;/code&gt;&lt;/pre&gt;
setLocale(&amp;lsquo;ja&amp;rsquo;)で日本語で表示するよう指定することができます。&lt;/p&gt;

&lt;p&gt;Pcikerで取得した内容はsetCallbackで指定した関数にJSONで渡されるので&lt;br /&gt;
これを適当に処理してやればおっけーです。&lt;/p&gt;

&lt;p&gt;以上です。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://gist.github.com/Daniel15/5994054&#34;&gt;Google Drive File Picker Example&lt;/a&gt;&lt;br /&gt;
Gistにもっと工夫したものがあったのでこれも参考にするといいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ASOBI&#43;のソースコードを公開しました。</title>
      <link>https://zaburo-ch.github.io/post/publishing_asobi_plus/</link>
      <pubDate>Mon, 29 Jun 2015 00:28:20 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/publishing_asobi_plus/</guid>
      <description>&lt;p&gt;去年の10月頃公開した&lt;a href=&#34;http://asobi.herokuapp.com/&#34;&gt;ASOBI+&lt;/a&gt;ですが、&lt;br /&gt;
最近はブラッシュアップすることもなくなり放置状態になっていたので、&lt;br /&gt;
Githubでソースコード、アイコン等を公開しました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/zaburo-ch/asobi_plus&#34;&gt;zaburo-ch/asobi_plus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Herokuで動いているものをほぼそのまま公開した形ですが、&lt;br /&gt;
APIkeyの部分だけ変えてあるのでそこ変えないと動きません。&lt;/p&gt;

&lt;p&gt;WebRTCを使ったWebアプリ等を作る際に役立てて頂ければと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【C&#43;&#43;】mainなどの関数の中では大きな配列を確保できない</title>
      <link>https://zaburo-ch.github.io/post/20150617_0/</link>
      <pubDate>Wed, 17 Jun 2015 02:48:23 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/20150617_0/</guid>
      <description>&lt;p&gt;これがSegmentation faultになるのに対して&lt;br /&gt;
&lt;script src=&#34;https://gist.github.com/zaburo-ch/f7a91485933876727a59.js&#34;&gt;&lt;/script&gt;&lt;br /&gt;
これは正しく実行される。&lt;br /&gt;
&lt;script src=&#34;https://gist.github.com/zaburo-ch/8c0bac865b2f9ddeb8f4.js&#34;&gt;&lt;/script&gt;&lt;br /&gt;
グローバル変数はヒープに取られるのに対して、&lt;br /&gt;
ローカル変数はスタックに積まれていく。&lt;br /&gt;
スタックのサイズは制限されていることが多く、&lt;br /&gt;
(bashならulimit -aで確認できる。8192KBだった)&lt;br /&gt;
bool型は1byteなので配列のサイズは10000001/1024≒9765KBとなり&lt;br /&gt;
スタックのサイズ制限を超えてしまうので、&lt;br /&gt;
メモリリミットより小さいがローカル変数として確保できない。&lt;/p&gt;

&lt;p&gt;[参考]&lt;br /&gt;
&lt;a href=&#34;http://homepage2.nifty.com/well/Variable.html&#34; target=&#34;_blank&#34; title=&#34;http://homepage2.nifty.com/well/Variable.html&#34;&gt;&lt;a href=&#34;http://homepage2.nifty.com/well/Variable.html&#34;&gt;http://homepage2.nifty.com/well/Variable.html&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2015/6/30 追記]&lt;br /&gt;
newでもいけるということをコメントで教えて頂きました。&lt;br /&gt;
なるほど確かにnewでもヒープに確保されますね。&lt;br /&gt;
newでいけるということは中でnew使ってくれてるvectorでもいけます。&lt;br /&gt;
&lt;script src=&#34;https://gist.github.com/zaburo-ch/a976a83edecd0eb952e9.js&#34;&gt;&lt;/script&gt;
ご指摘ありがとうございました！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【C&#43;&#43;】vectorは==で比較できる</title>
      <link>https://zaburo-ch.github.io/post/20150518_0/</link>
      <pubDate>Mon, 18 May 2015 19:18:45 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/20150518_0/</guid>
      <description>&lt;p&gt;知らなかったのでメモ&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cppll.jp/cppreference/cppvector_details.html&#34; target=&#34;_blank&#34; title=&#34;C++ ベクタ&#34;&gt;C++ ベクタ&lt;br /&gt;
&lt;a href=&#34;http://www.cppll.jp/cppreference/cppvector_details.html&#34;&gt;http://www.cppll.jp/cppreference/cppvector_details.html&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/zaburo-ch/56b43044d09bac1b603d.js&#34;&gt;&lt;/script&gt;&lt;br /&gt;
Javaでのオブジェクトの比較みたいに&lt;br /&gt;
アドレスが比較されちゃうんだと勘違いしてた。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wikipediaの記事でPageRankを計算してみた。</title>
      <link>https://zaburo-ch.github.io/post/20150514_1/</link>
      <pubDate>Thu, 14 May 2015 22:36:00 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/20150514_1/</guid>
      <description>&lt;p&gt;PageRankの記事の続きです。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://zaburo-ch.github.io/post/20150514_1/&#34; target=&#34;_blank&#34; title=&#34;【Python】PageRankアルゴリズム&#34;&gt;【Python】PageRankアルゴリズム&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;PageRank実装だけして終わるのももったいないので&lt;br /&gt;
Wikipediaのページ内でPageRank計算してみました。&lt;/p&gt;

&lt;p&gt;コードはこちら&lt;br /&gt;
&lt;a href=&#34;https://github.com/zaburo-ch/wikipedia_analysis&#34; target=&#34;_blank&#34; title=&#34;zaburo-ch/wikipedia_analysis&#34;&gt;zaburo-ch/wikipedia_analysis&lt;br /&gt;
&lt;a href=&#34;https://github.com/zaburo-ch/wikipedia_analysis&#34;&gt;https://github.com/zaburo-ch/wikipedia_analysis&lt;/a&gt;&lt;/a&gt;&lt;br /&gt;
前に作ったwikipedia.pyのコードとまとめてレポジトリにしました。&lt;/p&gt;

&lt;p&gt;pagerank_wiki.pyを実行すると次のような動作をします。&lt;br /&gt;
・&lt;a href=&#34;http://dumps.wikimedia.org&#34; target=&#34;_blank&#34; title=&#34;http://dumps.wikimedia.org&#34;&gt;&lt;a href=&#34;http://dumps.wikimedia.org&#34;&gt;http://dumps.wikimedia.org&lt;/a&gt;&lt;/a&gt;より1日分のデータを取得&lt;br /&gt;
・国コードがjaのもののうち閲覧数上位10000ページを取り出す&lt;br /&gt;
・各ページの記事内のリンクをエッジとした有向グラフつくる&lt;br /&gt;
・有向グラフ内でPageRankを計算し大きい順に出力する&lt;/p&gt;

&lt;p&gt;やってることはかなりwikipedia.pyに近いですが、&lt;br /&gt;
見返してみるとあまりにもなコードだったのでかなり書き換えました。&lt;br /&gt;
他にもリンク抽出にHTMLParser使ってみたりいろいろ変えてます。&lt;/p&gt;

&lt;p&gt;前のやつと違って計算の部分にそれほど時間がかからないので&lt;br /&gt;
スペック次第ですが少なくとも寝てる間くらいには終わると思います。&lt;br /&gt;
リンク解析もこっちのほうがかなり早いです。&lt;/p&gt;

&lt;p&gt;さて、肝心の実行結果はこんな感じです。&lt;br /&gt;
&lt;a href=&#34;https://zaburo-ch.github.io/images/pagerankwikiresult.png/&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://zaburo-ch.github.io/images/pagerankwikiresult.png&#34; alt=&#34;pagerankwikiresult.png&#34; border=&#34;0&#34; width=&#34;435&#34; height=&#34;400&#34; /&gt;&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://github.com/zaburo-ch/wikipedia_analysis/blob/master/pagerank_wiki_data/result.txt&#34; target=&#34;_blank&#34; title=&#34;wikipedia_analysis/pagerank_wiki_data/result.txt&#34;&gt;wikipedia_analysis/pagerank_wiki_data/result.txt&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;「特別:カテゴリ」がぶっちぎりで大きいですね。&lt;br /&gt;
確認してみたところほぼ全てのページの一番下に&lt;br /&gt;
「特別:カテゴリ」へのリンクがあったのでたぶんそのせいです。&lt;br /&gt;
「Wikipedia:出典を明記する」とかもこの類いかな。&lt;/p&gt;

&lt;p&gt;「日本」や年がおおいのは人とか何かの作品の記事の&lt;br /&gt;
テンプレート化している右の枠内で登場することが多いためだと思います。&lt;/p&gt;

&lt;p&gt;テレビ局が上位に多いのはテレビ番組からほぼ確実にリンクされているのと&lt;br /&gt;
閲覧数上位10000ページで限定しているため&lt;br /&gt;
そのなかでテレビ番組が多かったためではないかと考えています。&lt;/p&gt;

&lt;p&gt;上位はほとんどが誰でも知っているような一般的な言葉なんですが、&lt;br /&gt;
101位のインターネット・ムービー・データベースってやつ、&lt;br /&gt;
全然何のことかわからないです。&lt;br /&gt;
「集英社」とか「台湾」より上なので、&lt;br /&gt;
かなり多くページがここにリンクしてるはずなんですが、&lt;br /&gt;
これどんなページからリンクされてるんでしょう？&lt;/p&gt;

&lt;p&gt;全体的にPageRankはWikipediaのページの重要性判断としては&lt;br /&gt;
あまり向いていないように思いました。&lt;br /&gt;
WikipediaにはPageRankの基本的な考え方が合ってないですしね。&lt;br /&gt;
ほかのWebサイトでも試してみればもっと面白い結果が得られるかもしれません。&lt;br /&gt;
機会があればやってみたいと思います。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【Python】PageRankアルゴリズム</title>
      <link>https://zaburo-ch.github.io/post/20150514_0/</link>
      <pubDate>Thu, 14 May 2015 20:54:05 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/20150514_0/</guid>
      <description>&lt;p&gt;PageRankというアルゴリズム、&lt;br /&gt;
以前からなんとなくは知ってはいたのですが、&lt;br /&gt;
ランダムサーファーモデルで計算する方法を聞いて、&lt;br /&gt;
めちゃくちゃ賢いなこれーって思ったので実際にやってみました。&lt;/p&gt;

&lt;p&gt;ひとまずPageRankについて調べたことを纏めます。&lt;/p&gt;

&lt;p&gt;PageRankは基本的に次の２つの考え方でページの重要度を推定します。&lt;br /&gt;
・多くのページからリンクされているページの質は高い&lt;br /&gt;
・質の高いページからリンクされているページの質は高い&lt;/p&gt;

&lt;p&gt;これを数学的に考えるのにランダムサーファーモデルを利用します。&lt;br /&gt;
ランダムサーファーモデルでは&lt;br /&gt;
ページのリンク関係を有向グラフとして考え、&lt;br /&gt;
人(サーファー)にこの有向グラフをランダムに辿らせたとき、&lt;br /&gt;
人が居る確率が高いページを重要とします。&lt;/p&gt;

&lt;p&gt;まず、ページの総数をNとし、N次正方行列&lt;strong&gt;M&lt;/strong&gt;を&lt;br /&gt;
&lt;strong&gt;M&lt;/strong&gt;[i][j] = ページjにいるサーファーがページiに移動する確率&lt;br /&gt;
と定義します。&lt;br /&gt;
例えばページ0にページ1とページ5へのリンクしかないとすると、&lt;br /&gt;
サーファーはランダムに移動するので&lt;br /&gt;
&lt;strong&gt;M&lt;/strong&gt;[i][0]は i=1or5 のとき1/2 となりそれ以外のiでは0となります。&lt;/p&gt;

&lt;p&gt;また、ベクトル&lt;strong&gt;P&lt;/strong&gt;(t)を時刻tに各ページに人がいる確率とすると&lt;br /&gt;
&lt;strong&gt;P&lt;/strong&gt;(0)は全ての要素が 1/N のベクトルとなり&lt;br /&gt;
&lt;strong&gt;P&lt;/strong&gt;(t+1)は&lt;strong&gt;M&lt;/strong&gt;と&lt;strong&gt;P&lt;/strong&gt;(t)の積を取ることで計算できます。&lt;/p&gt;

&lt;p&gt;有向グラフが強連結のとき、この遷移を無限に繰り返すことで&lt;br /&gt;
&lt;strong&gt;P&lt;/strong&gt;はtに依らない一定の値に収束します。よってこの&lt;strong&gt;P&lt;/strong&gt;は&lt;br /&gt;
&lt;strong&gt;M P&lt;/strong&gt; = &lt;strong&gt;P&lt;/strong&gt;&lt;br /&gt;
の解を要素の和が1になるよう正規化してあげることにより求められます。&lt;/p&gt;

&lt;p&gt;この&lt;strong&gt;P&lt;/strong&gt;の大きさが各ページの重要度となります。&lt;/p&gt;

&lt;p&gt;行列計算において &lt;strong&gt;Ax&lt;/strong&gt; = λ&lt;strong&gt;x&lt;/strong&gt; を解く、というのは固有値問題と言って&lt;br /&gt;
色々な方法が考えられているらしいのですが、ここについては&lt;br /&gt;
&lt;a href=&#34;http://www.cms-initiative.jp/ja/events/0627yamamoto.pdf&#34; target=&#34;_blank&#34; title=&#34;行列計算における高速アルゴリズム&#34;&gt;行列計算における高速アルゴリズム&lt;br /&gt;
&lt;a href=&#34;http://www.cms-initiative.jp/ja/events/0627yamamoto.pdf&#34;&gt;http://www.cms-initiative.jp/ja/events/0627yamamoto.pdf&lt;/a&gt;&lt;br /&gt;
&lt;/a&gt;こちらのページが詳しいです。&lt;br /&gt;
Pythonではscipy.sparse.linalg.eigsを使うと&lt;br /&gt;
Implicitly Restarted Arnoldi で計算してくれます。&lt;br /&gt;
ただ、&lt;strong&gt;M P&lt;/strong&gt; = &lt;strong&gt;P&lt;/strong&gt; を解くだけのためにこれらを使うのが速いのかは&lt;br /&gt;
勉強不足で僕もよくわかっていません。&lt;/p&gt;

&lt;p&gt;実際のウェブページでは、ページ間の関係を有効グラフにしても&lt;br /&gt;
必ずしも上で述べたような強連結になるわけではありません。&lt;br /&gt;
そのため「一定の確率でサーファーはリンクを辿らずにランダムに移動する」&lt;br /&gt;
という考えを新たに導入します。その時はMにあたるものを&lt;br /&gt;
全ての要素が 1/N である N次正方行列Uと普通にリンクを辿る確率αを用いて&lt;br /&gt;
(α&lt;strong&gt;M&lt;/strong&gt; + (1-α)&lt;strong&gt;U&lt;/strong&gt;) として計算することによって&lt;strong&gt;P&lt;/strong&gt;が求められます。&lt;/p&gt;

&lt;p&gt;次の図のようなリンク関係にあるページのPageRankを&lt;br /&gt;
Pythonを利用して実際に計算してみます。&lt;br /&gt;
正しく計算できれば図の通りの値が得られるはずです。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://zaburo-ch.github.io/images/Linkstruct2.gif&#34; alt=&#34;Linkstruct2.gif&#34; border=&#34;0&#34; width=&#34;400&#34; height=&#34;368&#34; /&gt;&lt;br /&gt;
&lt;span style=&#34;font-size:x-small;&#34;&gt;&lt;br /&gt;
The original uploader was &lt;a title=&#34;wikipedia:User:Gnix&#34; href=&#34;//en.wikipedia.org/wiki/User:Gnix&#34;&gt;Gnix&lt;/a&gt; at &lt;a title=&#34;wikipedia:&#34; href=&#34;//en.wikipedia.org/wiki/&#34;&gt;English Wikipedia&lt;/a&gt;[&lt;a href=&#34;http://www.gnu.org/copyleft/fdl.html&#34; target=&#34;_blank&#34; title=&#34;GFDL&#34;&gt;GFDL&lt;/a&gt; or &lt;a href=&#34;http://creativecommons.org/licenses/by-sa/3.0/&#34; target=&#34;_blank&#34; title=&#34;CC-BY-SA-3.0&#34;&gt;CC-BY-SA-3.0&lt;/a&gt;]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;コードはこちら&lt;br /&gt;
&lt;a href=&#34;https://github.com/zaburo-ch/wikipedia_analysis/blob/master/pagerank.py&#34; target=&#34;_blank&#34; title=&#34;zaburo-ch/wikipedia_analysis/master/pagerank.py&#34;&gt;zaburo-ch/wikipedia_analysis/master/pagerank.py&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;get_pagerankではScipyを用いて固有ベクトルを計算しています。&lt;br /&gt;
get_pagerank_simpleではもっと単純に&lt;br /&gt;
&lt;strong&gt;P&lt;/strong&gt;(0)に何度も&lt;strong&gt;M&lt;/strong&gt;をかけていき、&lt;br /&gt;
かける前との差が十分小さくなるまで繰り返しています。&lt;/p&gt;

&lt;p&gt;実行結果はこんな感じです。&lt;br /&gt;
&lt;img src=&#34;https://zaburo-ch.github.io/images/pagerankresult.png&#34; alt=&#34;pagerankresult.png&#34; border=&#34;0&#34; width=&#34;273&#34; height=&#34;258&#34; /&gt;&lt;/p&gt;

&lt;p&gt;図の値とかなり一致していますね！&lt;br /&gt;
2つの方法どちらもほぼ同じ値になっているので&lt;br /&gt;
get_pagerank_simpleの方法でも十分実用に足りそうです。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>動的時間伸縮法(DTW)をPythonで試してみた</title>
      <link>https://zaburo-ch.github.io/post/20150406_0/</link>
      <pubDate>Mon, 06 Apr 2015 18:36:47 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/20150406_0/</guid>
      <description>&lt;p&gt;ここ数ヶ月くらい、ある時系列データを集めていたのですが、&lt;br /&gt;
そのデータを扱うにあたってまずデータを分類したいと思い&lt;br /&gt;
クラスタリングについて調べたところ&lt;br /&gt;
どうやらクラスタリングにはまず距離を定義しなければいけないらしい。&lt;/p&gt;

&lt;p&gt;時系列データの距離？は？と思っていたら&lt;br /&gt;
このようなページがありました。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://sinhrks.hatenablog.com/entry/2014/11/14/232603&#34; target=&#34;_blank&#34; title=&#34;動的時間伸縮法 / DTW (Dynamic Time Warping) を可視化する&#34;&gt;動的時間伸縮法 / DTW (Dynamic Time Warping) を可視化する&lt;br /&gt;
&lt;a href=&#34;http://sinhrks.hatenablog.com/entry/2014/11/14/232603&#34;&gt;http://sinhrks.hatenablog.com/entry/2014/11/14/232603&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Rの{TSculst}というパッケージを使えば簡単に計算できるそうですが、&lt;br /&gt;
有り難い事にDTW距離算出の実装を載せてくれているので&lt;br /&gt;
Python用に書き直してみました。&lt;/p&gt;

&lt;p&gt;&lt;script src=&#34;https://gist.github.com/zaburo-ch/6c16ecb3a4e25ee0d076.js&#34;&gt;&lt;/script&gt;&lt;br /&gt;
英語力低すぎて&lt;a href=&#34;http://en.wikipedia.org/wiki/Dynamic_time_warping&#34; target=&#34;_blank&#34; title=&#34;英語版Wikipedia&#34;&gt;英語版Wikipedia&lt;/a&gt;があまり理解できなかったのですが、&lt;br /&gt;
dは点同士の距離を定義する関数(初期値は差の絶対値)となる引数で、&lt;br /&gt;
windowは、ある点から距離を計算する対象となる点を&lt;br /&gt;
windowで指定した範囲に制限する場合の引数であってると思います。&lt;/p&gt;

&lt;p&gt;参考にさせて頂いたページにならって&lt;br /&gt;
RのデータセットAirPassengersでテストするようにしていますが、&lt;br /&gt;
PythonでRのデータセット利用する方法については&lt;br /&gt;
以下のページを参照してください。めっちゃ便利です。&lt;br /&gt;
&lt;a href=&#34;http://kumamotosan.hatenablog.com/entry/2014/03/02/231742&#34; target=&#34;_blank&#34; title=&#34;PythonでRの標準データセットを使う。http://kumamotosan.hatenablog.com/entry/2014/03/02/231742&#34;&gt;PythonでRの標準データセットを使う。&lt;br /&gt;
&lt;a href=&#34;http://kumamotosan.hatenablog.com/entry/2014/03/02/231742&#34;&gt;http://kumamotosan.hatenablog.com/entry/2014/03/02/231742&lt;/a&gt;&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【PokerStars】無料で使えるHUD更新した【ver0.3】</title>
      <link>https://zaburo-ch.github.io/post/20150327_1/</link>
      <pubDate>Fri, 27 Mar 2015 15:19:16 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/20150327_1/</guid>
      <description>&lt;p&gt;右下の白いタイルが動かないバグがあったため修正しました。&lt;/p&gt;

&lt;p&gt;こちらからアクセスしてダウンロードしてください！&lt;a href=&#34;https://github.com/zaburo-ch/poker_tool&#34; target=&#34;_blank&#34; title=&#34;zaburo-ch/poker_tool&#34;&gt;&lt;br /&gt;
zaburo-ch/poker_tool&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>【PokerStars】無料で使えるHUD更新した【ver0.2】</title>
      <link>https://zaburo-ch.github.io/post/20150327_0/</link>
      <pubDate>Fri, 27 Mar 2015 00:51:38 +0900</pubDate>
      
      <guid>https://zaburo-ch.github.io/post/20150327_0/</guid>
      <description>&lt;p&gt;同じデスクトップ内での多面打ちに対応しました。&lt;/p&gt;

&lt;p&gt;終了ボタンがあるウィンドウとHUD部分とを&lt;br /&gt;
別々のデスクトップおく事が出来ないため&lt;br /&gt;
同じデスクトップ内のみですが、複数のHUDを出せるようにしました。&lt;br /&gt;
プレイ画面を並べて多面する際に使って下さい！&lt;/p&gt;

&lt;p&gt;また、更新する度に使い方を載せるのは見づらくなるだけだと思ったので&lt;br /&gt;
GitHub上に使い方などを書いたREADME.mdと&lt;br /&gt;
アプリ本体をおく場所をつくりました。&lt;br /&gt;
こちらからアクセスしてダウンロードしてください！&lt;a href=&#34;https://github.com/zaburo-ch/poker_tool&#34; target=&#34;_blank&#34; title=&#34;zaburo-ch/poker_tool&#34;&gt;&lt;br /&gt;
zaburo-ch/poker_tool&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>