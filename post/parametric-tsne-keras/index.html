<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Parametric t-SNE を Keras で書いた &middot; ZABURO</title>
        <meta name="description" content="最近、t-SNEについていろいろ調べいて、その中でParametric t-SNEの論文を読みました。
元のt-SNEは可視化や次元削減の手法としてとても有用なのですが、 変換後の座標を乱数で初期化し、
KLダイバージェンスが小さくなるように勾配降下で座標を調整していく感じなので、
初めの乱数次第で配置は大きく変わりますし、別なデータを同じような場所に投射するようなことができません。
そのため、kaggleなどで前処理として使われる際には、
訓練データとテストデータをくっつけて変換するという方法が取られています。
しかし、本来見れないはずのテストデータを訓練データを変換する時にも使うというのはグレーな感じがします。
そこで、座標を直接調整するのではなく、
元の座標をパラメトリックな関数で低次元の座標に投射するようにして、
その関数のパラメータを学習してあげようというのがParametric t-SNEです。
ここで、関数としてニューラルネットが使われます。
論文では、RBMを重ねてpre trainingしてfine tuningというのをやっているのですが、
どうせやるならということで今風にReLUで書きました。
コードはここに置いてあります。
とりあえず論文にも載っているMNISTで試しました。
100 epoch回すとAWS EC2のg2.2xlargeインスタンスでだいたい10分程度かかります。
普通のMNISTなので60000件の訓練データと10000件のテストデータがあります。
学習していく過程が見れたら面白そうだなと思ったので、
各epoch終了後テストデータに対して変換を行い、散布図を書くようにしました。
結果はこんな感じ。
(なんかgifが吐けなくてmp4をgifに変換したので画質が悪い&hellip;)
訓練に使っていないデータに対してすごくいい感じに別けられていると思います。
10~20 epochくらいでいい感じに別けられているので、
10 epoch毎とかにミニバッチをシャッフルしてあげるともっと良くなるかもしれません。
一応shuffle_intervalという変数が用意してあって、
shuffle_interval回のepochが回るとミニバッチがシャッフルされてPが再計算されます。
Pを計算する部分についてもPython上でですが並列化してあるので少しは早いと思います。
Convolutional Parametric t-SNEだー！！って言って畳み込み層を使ったものも書いたのですが、
普通のMLP版とあまり変わらなかったのでお蔵入りしました。
いつもMNISTしてばかりなのでCIFAR-10でも試してみたのですがあまりうまくいきませんでした。
そもそもt-SNEでCIFAR-10がうまくいくのが試していないので良くわかりませんが、
これConvolutionalしてなんとか解決できないかなーと考えています。
追記：
逆変換も試しました。">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="generator" content="Hugo 0.41" />
        <meta name="robots" content="index,follow">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta property="og:title" content="Parametric t-SNE を Keras で書いた">
<meta property="og:description" content="最近、t-SNEについていろいろ調べいて、その中でParametric t-SNEの論文を読みました。
元のt-SNEは可視化や次元削減の手法としてとても有用なのですが、 変換後の座標を乱数で初期化し、
KLダイバージェンスが小さくなるように勾配降下で座標を調整していく感じなので、
初めの乱数次第で配置は大きく変わりますし、別なデータを同じような場所に投射するようなことができません。
そのため、kaggleなどで前処理として使われる際には、
訓練データとテストデータをくっつけて変換するという方法が取られています。
しかし、本来見れないはずのテストデータを訓練データを変換する時にも使うというのはグレーな感じがします。
そこで、座標を直接調整するのではなく、
元の座標をパラメトリックな関数で低次元の座標に投射するようにして、
その関数のパラメータを学習してあげようというのがParametric t-SNEです。
ここで、関数としてニューラルネットが使われます。
論文では、RBMを重ねてpre trainingしてfine tuningというのをやっているのですが、
どうせやるならということで今風にReLUで書きました。
コードはここに置いてあります。
とりあえず論文にも載っているMNISTで試しました。
100 epoch回すとAWS EC2のg2.2xlargeインスタンスでだいたい10分程度かかります。
普通のMNISTなので60000件の訓練データと10000件のテストデータがあります。
学習していく過程が見れたら面白そうだなと思ったので、
各epoch終了後テストデータに対して変換を行い、散布図を書くようにしました。
結果はこんな感じ。
(なんかgifが吐けなくてmp4をgifに変換したので画質が悪い&hellip;)
訓練に使っていないデータに対してすごくいい感じに別けられていると思います。
10~20 epochくらいでいい感じに別けられているので、
10 epoch毎とかにミニバッチをシャッフルしてあげるともっと良くなるかもしれません。
一応shuffle_intervalという変数が用意してあって、
shuffle_interval回のepochが回るとミニバッチがシャッフルされてPが再計算されます。
Pを計算する部分についてもPython上でですが並列化してあるので少しは早いと思います。
Convolutional Parametric t-SNEだー！！って言って畳み込み層を使ったものも書いたのですが、
普通のMLP版とあまり変わらなかったのでお蔵入りしました。
いつもMNISTしてばかりなのでCIFAR-10でも試してみたのですがあまりうまくいきませんでした。
そもそもt-SNEでCIFAR-10がうまくいくのが試していないので良くわかりませんが、
これConvolutionalしてなんとか解決できないかなーと考えています。
追記：
逆変換も試しました。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://zaburo-ch.github.io/post/parametric-tsne-keras/">
        <link rel="stylesheet" href="https://zaburo-ch.github.io/dist/styles.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,400,600,700,300&subset=latin,cyrillic-ext,latin-ext,cyrillic">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
        
        
        
    </head>
    <body>
        

        <div id="wrapper">
            <header class="site-header">
                <div class="container">
                    

                    <ul class="site-nav">
                        
    <li class="site-nav-item">
        <a title="Blog" href="/">Blog</a>
    </li>

    <li class="site-nav-item">
        <a title="About" href="/about/">About</a>
    </li>

    <li class="site-nav-item">
        <a title="Product" href="/product/">Product</a>
    </li>

    <li class="site-nav-item">
        <a title="Github" href="https://github.com/zaburo-ch">Github</a>
    </li>

                    </ul>
                </div>
            </header>

            <div id="container">


<div class="container">
    <article class="post-container" itemscope="" itemtype="http://schema.org/BlogPosting">
        <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Parametric t-SNE を Keras で書いた</h1>
    
    <p class="post-date">
        <span>Published <time datetime="2016-06-28" itemprop="datePublished">Tue, Jun 28, 2016</time></span>
        <span>by</span>
        <span itemscope="" itemprop="author" itemtype="https://schema.org/Person">
            <span itemprop="name">
                <a href="https://zaburo-ch.github.io/" itemprop="url" rel="author">ZABURO</a>
            </span>
        </span>
    </p>
</header>

        <div class="post-content clearfix" itemprop="articleBody">
    

    <p>最近、t-SNEについていろいろ調べいて、その中で<a href="https://lvdmaaten.github.io/publications/papers/AISTATS_2009.pdf">Parametric t-SNEの論文</a>を読みました。<br />
<a href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf">元のt-SNE</a>は可視化や次元削減の手法としてとても有用なのですが、
変換後の座標を乱数で初期化し、<br />
KLダイバージェンスが小さくなるように勾配降下で座標を調整していく感じなので、<br />
初めの乱数次第で配置は大きく変わりますし、別なデータを同じような場所に投射するようなことができません。</p>

<p>そのため、kaggleなどで前処理として使われる際には、<br />
訓練データとテストデータをくっつけて変換するという方法が取られています。<br />
しかし、本来見れないはずのテストデータを訓練データを変換する時にも使うというのはグレーな感じがします。</p>

<p>そこで、座標を直接調整するのではなく、<br />
元の座標をパラメトリックな関数で低次元の座標に投射するようにして、<br />
その関数のパラメータを学習してあげようというのがParametric t-SNEです。<br />
ここで、関数としてニューラルネットが使われます。</p>

<p>論文では、RBMを重ねてpre trainingしてfine tuningというのをやっているのですが、<br />
どうせやるならということで今風にReLUで書きました。</p>

<p>コードは<a href="https://github.com/zaburo-ch/Parametric-t-SNE-in-Keras">ここ</a>に置いてあります。<br />
とりあえず論文にも載っているMNISTで試しました。<br />
100 epoch回すとAWS EC2のg2.2xlargeインスタンスでだいたい10分程度かかります。</p>

<p>普通のMNISTなので60000件の訓練データと10000件のテストデータがあります。<br />
学習していく過程が見れたら面白そうだなと思ったので、<br />
各epoch終了後テストデータに対して変換を行い、散布図を書くようにしました。</p>

<p>結果はこんな感じ。<br />
<img src="/images/mnist_process.gif" alt="画像" /><br />
(なんかgifが吐けなくてmp4をgifに変換したので画質が悪い&hellip;)</p>

<p>訓練に使っていないデータに対してすごくいい感じに別けられていると思います。</p>

<p>10~20 epochくらいでいい感じに別けられているので、<br />
10 epoch毎とかにミニバッチをシャッフルしてあげるともっと良くなるかもしれません。<br />
一応shuffle_intervalという変数が用意してあって、<br />
shuffle_interval回のepochが回るとミニバッチがシャッフルされてPが再計算されます。</p>

<p>Pを計算する部分についてもPython上でですが並列化してあるので少しは早いと思います。</p>

<p>Convolutional Parametric t-SNEだー！！って言って畳み込み層を使ったものも書いたのですが、<br />
普通のMLP版とあまり変わらなかったのでお蔵入りしました。</p>

<p>いつもMNISTしてばかりなのでCIFAR-10でも試してみたのですがあまりうまくいきませんでした。<br />
そもそもt-SNEでCIFAR-10がうまくいくのが試していないので良くわかりませんが、<br />
これConvolutionalしてなんとか解決できないかなーと考えています。</p>

<p>追記：<br />
<a href="/post/tsne-decode/">逆変換も試しました。</a></p>

</div>

        <footer class="post-footer clearfix">
    
        <p class="post-tags">
            <span>Tagged:</span>
            
            
                <a href="/tags/python/">Python</a>, 
            
                <a href="/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92/">機械学習</a>, 
            
                <a href="/tags/%E5%8F%AF%E8%A6%96%E5%8C%96/">可視化</a>
            
        </p>
    

    <div class="share">
        
            <a class="icon-twitter" href="https://twitter.com/share?text=Parametric%20t-SNE%20%e3%82%92%20Keras%20%e3%81%a7%e6%9b%b8%e3%81%84%e3%81%9f&url=https%3a%2f%2fzaburo-ch.github.io%2fpost%2fparametric-tsne-keras%2f"
                onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fa fa-twitter"></i>
                <span class="hidden">Twitter</span>
            </a>
        

        
            <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fzaburo-ch.github.io%2fpost%2fparametric-tsne-keras%2f"
                onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                <i class="fa fa-facebook"></i>
                <span class="hidden">Facebook</span>
            </a>
        

        
            <a class="icon-google-plus" href="https://plus.google.com/share?url=https%3a%2f%2fzaburo-ch.github.io%2fpost%2fparametric-tsne-keras%2f"
              onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
              <i class="fa fa-google-plus"></i>
                <span class="hidden">Google+</span>
            </a>
        
        
    </div>
</footer>



        
    <div class="comments">
        
    </div>

    </article>
</div>

            </div>
        </div>

        <footer class="footer">
            <div class="container">
                <div class="site-title-wrapper">
                    <h1 class="site-title">
                        <a title="ZABURO app" href="https://zaburo-ch.github.io/">ZABURO app</a>
                    </h1>
                    <a class="button-square button-jump-top js-jump-top" href="#">
                        <i class="fa fa-angle-up"></i>
                    </a>
                </div>

                <p class="footer-copyright">
                    <span>&copy; 2018 / Powered by <a href="https://gohugo.io/">Hugo</a></span>
                </p>
                <p class="footer-copyright">
                    <span><a href="https://github.com/roryg/ghostwriter">Ghostwriter theme</a> By <a href="http://jollygoodthemes.com">JollyGoodThemes</a></span>
                    <span>/ <a href="https://github.com/jbub/ghostwriter">Ported</a> to Hugo By <a href="https://github.com/jbub">jbub</a></span>
                </p>
            </div>
        </footer>

        <script src="https://zaburo-ch.github.io/js/jquery-1.11.3.min.js"></script>
        <script src="https://zaburo-ch.github.io/js/jquery.fitvids.js"></script>
        
        
            <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        
        
        <script src="https://zaburo-ch.github.io/js/scripts.js"></script>
    </body>
</html>

